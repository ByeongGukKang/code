{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.api import OLS, add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cagr(return_df):\n",
    "    '''rtn을 받았을 때, CAGR을 계산합니다'''\n",
    "    holding_year = (len(return_df) / 365)\n",
    "    cum = (return_df+1).cumprod()\n",
    "    cagr = (cum.iloc[-1] / cum.iloc[0]) ** (1/holding_year) -1\n",
    "    return cagr\n",
    "\n",
    "def run_alpha_regression(return_dict:dict, \n",
    "                         mkt_rtn:pd.DataFrame,\n",
    "                         constant=True):\n",
    "    \n",
    "    '''return_dict : 포트폴리오 리턴(dict)\n",
    "       mkt_rtn : 마켓 인덱스의 리턴이 들어감\n",
    "       constant : True(Default)/ False\n",
    "       '''\n",
    "    \n",
    "    for key, strategy_df in return_dict.items():  \n",
    "        if str(key) ==\"count\":\n",
    "            continue\n",
    "        \n",
    "        if constant:\n",
    "            model = OLS(strategy_df, add_constant(mkt_rtn))\n",
    "        else:\n",
    "            model = OLS(strategy_df, mkt_rtn)\n",
    "        result = model.fit()\n",
    "        \n",
    "        print(f\"{key} Regression Result\")\n",
    "        print(result.summary2())\n",
    "        \n",
    "def print_statistics(return_dict:dict,\n",
    "                     mkt_rtn:pd.DataFrame):\n",
    "        \n",
    "    mean = [df.mean().round(6) for key, df in return_dict.items()]          \n",
    "    std = [df.std() for key, df in return_dict.items()]\n",
    "    cagr =[calculate_cagr(df) * 100 for key, df in return_dict.items()]          \n",
    "    return_df = pd.DataFrame([cagr,mean,std], \n",
    "                             index=[\"CAGR\", \"Mean\",\"STD\"])\n",
    "    \n",
    "    \n",
    "    mkt = pd.DataFrame([calculate_cagr(mkt_rtn) * 100, mkt_rtn.mean(), mkt_rtn.std()],\n",
    "                           index=[\"CAGR\", \"Mean\",\"STD\"], \n",
    "                           columns=[\"MKT\"])\n",
    "    \n",
    "    return_df = pd.concat([return_df, mkt], axis=1)\n",
    "    return_df.loc[\"Shape\",:] = (return_df.loc[\"Mean\",:]*365)/ (return_df.loc[\"STD\",:]*np.sqrt(365))\n",
    "    return return_df\n",
    "        \n",
    "def draw_return_result(return_dict:dict, \n",
    "                       with_mkt=False,\n",
    "                       mkt_rtn=None):\n",
    "    \n",
    "    '''rtn_result : dict(리턴이 담긴 딕셔러니)\n",
    "       with_mkt   : bool -> 마켓인덱스를 함께 그릴지 표시\n",
    "       with_mkt가 True일 경우 mkt_rtn을 줘야한다'''\n",
    "        \n",
    "    for key, df in return_dict.items():\n",
    "        fig, axes = plt.subplots(3,1, sharex=True, figsize=(24,24), \n",
    "                                 gridspec_kw={'height_ratios': [4, 1, 1]})\n",
    "        cum_df = (df+1).cumprod()\n",
    "        cum_df.plot(ax=axes[0])\n",
    "            \n",
    "        axes[0].set_title(\"Cross-Sectional Momentum Cummulative returns weighted by marketcap\")\n",
    "        axes[0].grid()\n",
    "        axes[0].legend([\"Startegy\",\"MKT\"])\n",
    "        \n",
    "        peak = cum_df.cummax()\n",
    "        drawdown = (cum_df-peak)/peak\n",
    "        drawdown.plot(ax=axes[1])\n",
    "        axes[1].set_title(\"Draw Down\")\n",
    "        axes[1].grid()\n",
    "        \n",
    "        df.plot(ax=axes[2])\n",
    "        axes[2].grid()\n",
    "        \n",
    "        if with_mkt:\n",
    "            mktcum = (mkt_rtn+1).cumprod()\n",
    "            mktcum.plot(ax=axes[0])\n",
    "            axes[0].grid()\n",
    "            axes[0].legend([\"Startegy\",\"MKT\"])\n",
    "            \n",
    "            peak = mktcum.cummax()\n",
    "            drawdown = (mktcum-peak) / peak\n",
    "            drawdown.plot(ax=axes[1], alpha=0.3)\n",
    "            axes[1].grid()\n",
    "            \n",
    "            mkt_rtn.plot(ax=axes[2], alpha=0.3)\n",
    "            axes[2].grid();      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 마켓인덱스\n",
    "\n",
    "Vol 0으로 스크리닝한 Return 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mktcap = pd.read_pickle(\"ryu_new_mktcap9.pickle\")\n",
    "price = pd.read_pickle(\"ryu_new_price9.pickle\")\n",
    "vol = pd.read_pickle(\"ryu_new_volume9.pickle\")\n",
    "\n",
    "rtn = price.pct_change(fill_method=None) * np.sign(price)\n",
    "#weight = mktcap.apply(lambda x: x/ np.nansum(x), axis=1)\n",
    "\n",
    "vol_mask = (vol > 0).replace(False, np.nan)\n",
    "new_mktcap = (vol_mask * mktcap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_mktcap이 0보다 큰 날을 찾아보자\n",
    "sum_num = (~new_mktcap.isna()).sum(1)\n",
    "sum_num.loc[sum_num>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weight = new_mktcap.loc[\"2013-12-27\":].apply(lambda x:x/np.nansum(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1)\n",
    "\n",
    "# 마켓 리턴      \"2013-12-27\"\n",
    "mkt_rtn = ((rtn.loc[:] * new_weight).sum(1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Sectional : Weekly Rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mktcap = pd.read_pickle(\"ryu_new_mktcap9.pickle\")\n",
    "price  = pd.read_pickle(\"ryu_new_price9.pickle\")\n",
    "vol = pd.read_pickle(\"ryu_new_volume9.pickle\")\n",
    "\n",
    "daily_rtn = price.pct_change(fill_method=None) * np.sign(price)\n",
    "vol_screener = (vol > 0).replace({True:1, \n",
    "                                  False:np.nan})\n",
    "\n",
    "# vol>0 은 너무 당연한거라 변수명을 그냥 daily, weekly로만 해주겠음\n",
    "daily_mktcap = vol_screener * mktcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언제부터 시작하는 지 찾자 (최소 100개의 코인이 필요)\n",
    "cnt = daily_mktcap.count(1)\n",
    "cnt.loc[cnt > 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return도 같은 기간으로 잘라야함\n",
    "start_date = \"2017-05-02\"\n",
    "daily_rtn_sample = daily_rtn.loc[start_date:]\n",
    "daily_mktcap_sample = daily_mktcap.loc[start_date:]\n",
    "\n",
    "# 나중에 plot할때도 필요해서 market rtn도 구해둬야한다\n",
    "mktrtn_sample = mkt_rtn.loc[\"2017-05-02\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 그룹의 filter를 구하고, 그것을 mkt와 곱한이후, 각 그룹의 weight를 구해야하는데, mktcap과 곱하는 과정에서 없어지는 코인이 너무 많은것\n",
    "## 해결 -> mktcap으로 마스킹\n",
    "\n",
    "## 우선 mktcap에 음수값이 있는 지 확인\n",
    "print((daily_mktcap_sample <= 0).sum().sum())\n",
    "\n",
    "daily_rtn_sample_pp = daily_rtn_sample * np.sign(daily_mktcap_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank를 계산해줍니다\n",
    "rank = daily_rtn_sample_pp.rank(axis=1, method=\"first\")\n",
    "\n",
    "# rank가 존재하는 코인의 수를 구합니다\n",
    "coin_count = rank.count(axis=1)\n",
    "\n",
    "# 그룹별로 동일한 코인 수를 포함하기 위해 각 그룹의 rank thresh를 생성해줍니다\n",
    "rank_thresh = coin_count.apply(lambda x: [i for i in range(0,x, x//5)])\n",
    "\n",
    "t1 = rank_thresh.apply(lambda x: x[1])\n",
    "t2 = rank_thresh.apply(lambda x: x[2])\n",
    "t3 = rank_thresh.apply(lambda x: x[3])\n",
    "t4 = rank_thresh.apply(lambda x: x[4])\n",
    "\n",
    "rank_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_mask = rank.apply(lambda x: x <= t1, axis=0) \\\n",
    "              .replace({True:1, False:np.nan})\n",
    "g2_mask = rank.apply(lambda x: (t1 < x)&(x <= t2), axis=0) \\\n",
    "              .replace({True:1, False:np.nan})\n",
    "g3_mask = rank.apply(lambda x: (t2 < x)&(x <= t3), axis=0) \\\n",
    "              .replace({True:1, False:np.nan})\n",
    "g4_mask = rank.apply(lambda x: (t3 < x)&(x <= t4), axis=0) \\\n",
    "              .replace({True:1, False:np.nan})\n",
    "g5_mask = rank.apply(lambda x: x > t4, axis=0) \\\n",
    "              .replace({True:1, False:np.nan})           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 그룹별 weight를 생성\n",
    "weight_g1 = (g1_mask * daily_mktcap_sample).apply(lambda x: x/np.nansum(x), axis=1)\n",
    "weight_g2 = (g2_mask * daily_mktcap_sample).apply(lambda x: x/np.nansum(x), axis=1)\n",
    "weight_g3 = (g3_mask * daily_mktcap_sample).apply(lambda x: x/np.nansum(x), axis=1)\n",
    "weight_g4 = (g4_mask * daily_mktcap_sample).apply(lambda x: x/np.nansum(x), axis=1)\n",
    "weight_g5 = (g5_mask * daily_mktcap_sample).apply(lambda x: x/np.nansum(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 코인 개수 출력 \n",
    "concat = pd.concat([weight_g1.count(1), weight_g2.count(1),\n",
    "                    weight_g3.count(1), weight_g4.count(1),\n",
    "                    weight_g5.count(1)], axis=1)#.plot();\n",
    "\n",
    "coin = pd.concat([concat, concat.sum(1)], axis=1)\n",
    "coin.columns = [0,1,2,3,4,\"Sum\"]\n",
    "\n",
    "coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter를 마켓켑과 리턴에 곱해줘서 각 그룹별 리턴 계산\n",
    "rtn_g1 = (daily_rtn_sample * weight_g1.shift(1)).sum(1)\n",
    "rtn_g2 = (daily_rtn_sample * weight_g2.shift(1)).sum(1)\n",
    "rtn_g3 = (daily_rtn_sample * weight_g3.shift(1)).sum(1)\n",
    "rtn_g4 = (daily_rtn_sample * weight_g4.shift(1)).sum(1)\n",
    "rtn_g5 = (daily_rtn_sample * weight_g5.shift(1)).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtn_dict = {\"Q1\":rtn_g1,\n",
    "            \"Q2\":rtn_g2,\n",
    "            \"Q3\":rtn_g3,\n",
    "            \"Q4\":rtn_g4,\n",
    "            \"Q5\":rtn_g5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_return_result(rtn_dict, with_mkt=True, mkt_rtn=mktrtn_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics(rtn_dict,\n",
    "                 mkt_rtn=mktrtn_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_alpha_regression(rtn_dict,\n",
    "                     mkt_rtn=mktrtn_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
